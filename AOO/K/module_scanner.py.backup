"""
æ¨¡å—æ‰«æå™¨ - ä¿®å¤ç‰ˆï¼ˆä½¿ç”¨ASTåˆ†æï¼‰
è´Ÿè´£è‡ªåŠ¨å‘ç°ã€åˆ†æå’Œæ³¨å†ŒAOOæ¡†æ¶ä¸­çš„æ‰€æœ‰æ¨¡å—
æ”¯æŒæ·±åº¦æ‰«æã€ç±»åˆ†æã€ä¾èµ–æ£€æµ‹å’Œæ€§èƒ½ä¼˜åŒ–
"""

import os
import sys
import ast
import time
import logging
from typing import Dict, List, Any, Optional, Set
from pathlib import Path
from dataclasses import dataclass
from enum import Enum
from concurrent.futures import ThreadPoolExecutor, as_completed

@dataclass
class ClassInfo:
    """ç±»ä¿¡æ¯æ•°æ®ç±»"""
    name: str
    module: str
    zone: str
    file_path: str
    bases: List[str]
    docstring: Optional[str]
    methods: List[str]
    attributes: List[str]
    is_abstract: bool
    is_discoverable: bool
    priority: int
    service_type: str

@dataclass
class ModuleInfo:
    """æ¨¡å—ä¿¡æ¯æ•°æ®ç±»"""
    zone: str
    name: str
    file_path: str
    classes: List[ClassInfo]
    imports: List[str]
    analysis_success: bool
    error: Optional[str]
    analysis_time: float
    file_size: int
    last_modified: float

class AnalysisLevel(Enum):
    """åˆ†æçº§åˆ«æšä¸¾"""
    QUICK = "quick"        # å¿«é€Ÿåˆ†æï¼Œåªæ£€æŸ¥ç±»å®šä¹‰
    BASIC = "basic"        # åŸºç¡€åˆ†æï¼Œæ£€æŸ¥ç±»å’Œæ–¹æ³•
    DETAILED = "detailed"  # è¯¦ç»†åˆ†æï¼ŒåŒ…æ‹¬å±æ€§å’Œä¾èµ–
    DEEP = "deep"          # æ·±åº¦åˆ†æï¼Œå®Œæ•´ASTè§£æ

class ModuleScanner:
    """æ¨¡å—æ‰«æå™¨ - ä½¿ç”¨ASTåˆ†æçš„ç”Ÿäº§ç¯å¢ƒçº§åˆ«å®ç°"""
    
    def __init__(self, aoo_root: str, config_manager=None):
        self.aoo_root = Path(aoo_root).resolve()
        self.config_manager = config_manager
        
        # é…ç½®
        self.ignore_dirs = {'__pycache__', '.git', 'config', 'logs', 'tests', 'temp', 'backup', 'data'}
        self.ignore_files = {'__init__.py', 'test_', '_test.py', 'conftest.py'}
        self.max_file_size = 10 * 1024 * 1024  # 10MB
        self.analysis_level = AnalysisLevel.DETAILED
        self.enable_parallel_scan = True
        self.max_workers = 8
        self.cache_enabled = True
        self.scan_timeout = 60  # ç§’
        
        # çŠ¶æ€å’Œç¼“å­˜
        self._scan_cache = {}
        self._last_scan_time = 0
        self._cache_ttl = 600  # 10åˆ†é’Ÿ
        
        # æ€§èƒ½ç»Ÿè®¡
        self._scan_stats = {
            'total_scans': 0,
            'total_modules': 0,
            'total_classes': 0,
            'total_discoverable': 0,
            'total_errors': 0,
            'total_scan_time': 0
        }
        
        # æ—¥å¿—
        self.logger = logging.getLogger('AOO.Scanner')
        
        # åŠ è½½é…ç½®
        self._load_config()
    
    def _load_config(self):
        """åŠ è½½é…ç½®"""
        if self.config_manager:
            try:
                scanner_config = self.config_manager.get_section('scanner') or {}
                self.ignore_dirs = set(scanner_config.get('ignore_dirs', self.ignore_dirs))
                self.ignore_files = set(scanner_config.get('ignore_files', self.ignore_files))
                self.max_file_size = scanner_config.get('max_file_size', self.max_file_size)
                self.enable_parallel_scan = scanner_config.get('enable_parallel_scan', self.enable_parallel_scan)
                self.max_workers = scanner_config.get('max_workers', self.max_workers)
                self.cache_enabled = scanner_config.get('cache_enabled', self.cache_enabled)
                self.scan_timeout = scanner_config.get('scan_timeout', self.scan_timeout)
                
                analysis_level_str = scanner_config.get('analysis_level', 'detailed')
                self.analysis_level = AnalysisLevel(analysis_level_str)
            except Exception as e:
                self.logger.warning(f"åŠ è½½æ‰«æå™¨é…ç½®å¤±è´¥: {e}")
    
    def discover_zones(self) -> List[str]:
        """å‘ç°æ‰€æœ‰åŒºåŸŸç›®å½•"""
        zones = []
        try:
            for item in self.aoo_root.iterdir():
                if (item.is_dir() and 
                    item.name.isalpha() and 
                    len(item.name) == 1 and
                    item.name not in self.ignore_dirs):
                    zones.append(item.name)
        except Exception as e:
            self.logger.error(f"å‘ç°åŒºåŸŸç›®å½•å¤±è´¥: {e}")
        
        return sorted(zones)
    
    def scan_zone(self, zone: str) -> List[str]:
        """æ‰«ææŒ‡å®šåŒºåŸŸçš„æ¨¡å—æ–‡ä»¶"""
        zone_path = self.aoo_root / zone
        if not zone_path.exists():
            self.logger.warning(f"åŒºåŸŸç›®å½•ä¸å­˜åœ¨: {zone}")
            return []
        
        modules = []
        try:
            for py_file in zone_path.glob("*.py"):
                if (py_file.name not in self.ignore_files and 
                    not py_file.name.startswith("_") and
                    py_file.stat().st_size <= self.max_file_size):
                    modules.append(py_file.stem)
        except Exception as e:
            self.logger.error(f"æ‰«æåŒºåŸŸ {zone} å¤±è´¥: {e}")
        
        return sorted(modules)
    
    def analyze_module(self, zone: str, module_name: str) -> ModuleInfo:
        """åˆ†ææ¨¡å—ï¼Œæå–è¯¦ç»†ä¿¡æ¯ - ä¿®å¤ç‰ˆ"""
        start_time = time.time()
        file_path = self.aoo_root / zone / f"{module_name}.py"
        
        try:
            # è·å–æ–‡ä»¶ä¿¡æ¯
            file_stat = file_path.stat()
            file_size = file_stat.st_size
            last_modified = file_stat.st_mtime
            
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"{zone}.{module_name}"
            if (self.cache_enabled and 
                cache_key in self._scan_cache and 
                self._scan_cache[cache_key]['last_modified'] == last_modified):
                return self._scan_cache[cache_key]['module_info']
            
            # æ ¹æ®åˆ†æçº§åˆ«é€‰æ‹©åˆ†ææ–¹æ³• - å…¨éƒ¨ä½¿ç”¨ASTåˆ†æ
            if self.analysis_level == AnalysisLevel.QUICK:
                module_info = self._analyze_module_quick(zone, module_name, file_path)
            elif self.analysis_level == AnalysisLevel.BASIC:
                module_info = self._analyze_module_basic(zone, module_name, file_path)
            elif self.analysis_level == AnalysisLevel.DETAILED:
                module_info = self._analyze_module_detailed(zone, module_name, file_path)
            else:  # DEEP
                module_info = self._analyze_module_deep(zone, module_name, file_path)
            
            # æ·»åŠ æ–‡ä»¶ä¿¡æ¯
            module_info.file_size = file_size
            module_info.last_modified = last_modified
            module_info.analysis_time = time.time() - start_time
            
            # æ›´æ–°ç¼“å­˜
            if self.cache_enabled:
                self._scan_cache[cache_key] = {
                    'module_info': module_info,
                    'last_modified': last_modified,
                    'cached_time': time.time()
                }
            
            return module_info
            
        except Exception as e:
            analysis_time = time.time() - start_time
            self.logger.error(f"åˆ†ææ¨¡å—å¤±è´¥ {zone}.{module_name}: {e}")
            
            return ModuleInfo(
                zone=zone,
                name=module_name,
                file_path=str(file_path),
                classes=[],
                imports=[],
                analysis_success=False,
                error=str(e),
                analysis_time=analysis_time,
                file_size=0,
                last_modified=0
            )
    
    def _analyze_module_quick(self, zone: str, module_name: str, file_path: Path) -> ModuleInfo:
        """å¿«é€Ÿåˆ†ææ¨¡å— - åªæ£€æŸ¥ç±»å®šä¹‰"""
        classes = []
        
        try:
            # ä½¿ç”¨ASTå¿«é€Ÿè§£æ
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    class_info = ClassInfo(
                        name=node.name,
                        module=f"{zone}.{module_name}",
                        zone=zone,
                        file_path=str(file_path),
                        bases=[base.id for base in node.bases if isinstance(base, ast.Name)],
                        docstring=ast.get_docstring(node),
                        methods=[],
                        attributes=[],
                        is_abstract=False,
                        is_discoverable=self._is_discoverable_class_quick(node),
                        priority=0,
                        service_type="singleton"
                    )
                    classes.append(class_info)
        except Exception as e:
            self.logger.warning(f"å¿«é€Ÿåˆ†ææ¨¡å—å¤±è´¥ {zone}.{module_name}: {e}")
        
        return ModuleInfo(
            zone=zone,
            name=module_name,
            file_path=str(file_path),
            classes=classes,
            imports=[],
            analysis_success=True,
            error=None,
            analysis_time=0,
            file_size=0,
            last_modified=0
        )
    
    def _analyze_module_basic(self, zone: str, module_name: str, file_path: Path) -> ModuleInfo:
        """åŸºç¡€åˆ†ææ¨¡å— - ä½¿ç”¨ASTæ£€æŸ¥ç±»å’Œæ–¹æ³•"""
        return self._analyze_module_with_ast(zone, module_name, file_path, basic=True)
    
    def _analyze_module_detailed(self, zone: str, module_name: str, file_path: Path) -> ModuleInfo:
        """è¯¦ç»†åˆ†ææ¨¡å— - ä½¿ç”¨ASTåŒ…æ‹¬å±æ€§å’ŒåŸºç¡€ä¾èµ–"""
        return self._analyze_module_with_ast(zone, module_name, file_path, basic=False)
    
    def _analyze_module_deep(self, zone: str, module_name: str, file_path: Path) -> ModuleInfo:
        """æ·±åº¦åˆ†ææ¨¡å— - ä½¿ç”¨ASTå®Œæ•´è§£æå’Œä¾èµ–åˆ†æ"""
        classes = []
        imports = []
        
        try:
            # ä½¿ç”¨ASTæ·±åº¦è§£æ
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            
            # åˆ†æå¯¼å…¥
            imports = self._analyze_imports(tree)
            
            # åˆ†æç±»
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    class_info = self._analyze_class_deep(node, zone, module_name, file_path)
                    classes.append(class_info)
                    
        except Exception as e:
            self.logger.error(f"æ·±åº¦åˆ†ææ¨¡å—å¤±è´¥ {zone}.{module_name}: {e}")
            raise
        
        return ModuleInfo(
            zone=zone,
            name=module_name,
            file_path=str(file_path),
            classes=classes,
            imports=imports,
            analysis_success=True,
            error=None,
            analysis_time=0,
            file_size=0,
            last_modified=0
        )
    
    def _analyze_module_with_ast(self, zone: str, module_name: str, file_path: Path, basic: bool = False) -> ModuleInfo:
        """ä½¿ç”¨ASTåˆ†ææ¨¡å— - æ›¿ä»£åŠ¨æ€å¯¼å…¥çš„å®‰å…¨æ–¹æ¡ˆ"""
        classes = []
        imports = []
        
        try:
            # ä½¿ç”¨ASTè§£æ
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            
            # åˆ†æå¯¼å…¥
            imports = self._analyze_imports(tree)
            
            # åˆ†æç±»
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    if basic:
                        class_info = self._analyze_class_basic_ast(node, zone, module_name, file_path)
                    else:
                        class_info = self._analyze_class_detailed_ast(node, zone, module_name, file_path)
                    classes.append(class_info)
                    
        except Exception as e:
            self.logger.error(f"ASTåˆ†ææ¨¡å—å¤±è´¥ {zone}.{module_name}: {e}")
            raise
        
        return ModuleInfo(
            zone=zone,
            name=module_name,
            file_path=str(file_path),
            classes=classes,
            imports=imports,
            analysis_success=True,
            error=None,
            analysis_time=0,
            file_size=0,
            last_modified=0
        )
    
    def _analyze_class_basic_ast(self, class_node: ast.ClassDef, zone: str, module_name: str, file_path: Path) -> ClassInfo:
        """åŸºç¡€åˆ†æç±»ï¼ˆä½¿ç”¨ASTï¼‰"""
        # è·å–åŸºç±»
        bases = []
        for base in class_node.bases:
            if isinstance(base, ast.Name):
                bases.append(base.id)
        
        # è·å–æ–¹æ³•
        methods = []
        for node in class_node.body:
            if isinstance(node, ast.FunctionDef):
                if not node.name.startswith('_'):
                    methods.append(node.name)
        
        return ClassInfo(
            name=class_node.name,
            module=f"{zone}.{module_name}",
            zone=zone,
            file_path=str(file_path),
            bases=bases,
            docstring=ast.get_docstring(class_node),
            methods=methods,
            attributes=[],
            is_abstract=False,
            is_discoverable=self._is_discoverable_class_quick(class_node),
            priority=0,
            service_type="singleton"
        )
    
    def _analyze_class_detailed_ast(self, class_node: ast.ClassDef, zone: str, module_name: str, file_path: Path) -> ClassInfo:
        """è¯¦ç»†åˆ†æç±»ï¼ˆä½¿ç”¨ASTï¼‰"""
        # è·å–åŸºç±»
        bases = []
        for base in class_node.bases:
            if isinstance(base, ast.Name):
                bases.append(base.id)
        
        # è·å–æ–¹æ³•
        methods = []
        attributes = []
        
        for node in class_node.body:
            if isinstance(node, ast.FunctionDef):
                if not node.name.startswith('_'):
                    methods.append(node.name)
            elif isinstance(node, ast.Assign):
                # æå–ç±»å±æ€§
                for target in node.targets:
                    if isinstance(target, ast.Name) and not target.id.startswith('_'):
                        attributes.append(target.id)
        
        return ClassInfo(
            name=class_node.name,
            module=f"{zone}.{module_name}",
            zone=zone,
            file_path=str(file_path),
            bases=bases,
            docstring=ast.get_docstring(class_node),
            methods=methods,
            attributes=attributes,
            is_abstract=False,
            is_discoverable=self._is_discoverable_class_quick(class_node),
            priority=0,
            service_type="singleton"
        )
    
    def _analyze_class_deep(self, class_node: ast.ClassDef, zone: str, module_name: str, file_path: Path) -> ClassInfo:
        """æ·±åº¦åˆ†æç±»ï¼ˆä½¿ç”¨ASTï¼‰"""
        # è·å–åŸºç±»
        bases = []
        for base in class_node.bases:
            if isinstance(base, ast.Name):
                bases.append(base.id)
        
        # è·å–æ–¹æ³•å’Œå±æ€§
        methods = []
        attributes = []
        
        for node in class_node.body:
            if isinstance(node, ast.FunctionDef):
                if not node.name.startswith('_'):
                    methods.append(node.name)
            elif isinstance(node, ast.Assign):
                for target in node.targets:
                    if isinstance(target, ast.Name) and not target.id.startswith('_'):
                        attributes.append(target.id)
        
        # æ£€æŸ¥æ˜¯å¦å¯å‘ç°ï¼ˆé€šè¿‡åŸºç±»åå’Œè£…é¥°å™¨ï¼‰
        is_discoverable = self._is_discoverable_class_quick(class_node)
        
        return ClassInfo(
            name=class_node.name,
            module=f"{zone}.{module_name}",
            zone=zone,
            file_path=str(file_path),
            bases=bases,
            docstring=ast.get_docstring(class_node),
            methods=methods,
            attributes=attributes,
            is_abstract=False,  # ASTæ— æ³•å‡†ç¡®åˆ¤æ–­
            is_discoverable=is_discoverable,
            priority=0,
            service_type="singleton"
        )
    
    def _analyze_imports(self, tree: ast.AST) -> List[str]:
        """åˆ†æå¯¼å…¥è¯­å¥"""
        imports = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.append(alias.name)
            elif isinstance(node, ast.ImportFrom):
                module = node.module or ""
                for alias in node.names:
                    imports.append(f"{module}.{alias.name}" if module else alias.name)
        
        return imports
    
    def _is_discoverable_class_quick(self, class_node: ast.ClassDef) -> bool:
        """å¿«é€Ÿæ£€æŸ¥ç±»æ˜¯å¦å¯å‘ç°ï¼ˆä½¿ç”¨ASTï¼‰"""
        # æ£€æŸ¥åŸºç±»
        base_names = []
        for base in class_node.bases:
            if isinstance(base, ast.Name):
                base_names.append(base.id)
        
        discoverable_base_names = {
            'BaseModule', 'DiscoverableModule', 'FactoryModule', 
            'ServiceModule', 'TradingModule'
        }
        
        if any(base in discoverable_base_names for base in base_names):
            return True
        
        # æ£€æŸ¥è£…é¥°å™¨
        for decorator in class_node.decorator_list:
            if isinstance(decorator, ast.Name):
                if decorator.id in ['discoverable', 'trading_module']:
                    return True
            elif isinstance(decorator, ast.Call):
                if isinstance(decorator.func, ast.Name) and decorator.func.id in ['discoverable', 'trading_module']:
                    return True
        
        return False
    
    def deep_scan(self, use_cache: bool = True) -> Dict[str, List[ModuleInfo]]:
        """æ‰§è¡Œæ·±åº¦æ‰«æ"""
        start_time = time.time()
        self.logger.info("ğŸ” å¼€å§‹æ·±åº¦æ‰«æAOOæ¡†æ¶...")
        self.logger.info(f"ğŸ“ æ‰«ææ ¹ç›®å½•: {self.aoo_root}")
        
        # æ£€æŸ¥ç¼“å­˜
        if (use_cache and self.cache_enabled and 
            time.time() - self._last_scan_time < self._cache_ttl and
            self._scan_cache):
            
            # ä»ç¼“å­˜é‡å»ºç»“æœ
            scan_results = {}
            for cache_key, cache_data in self._scan_cache.items():
                zone, module_name = cache_key.split('.', 1)
                if zone not in scan_results:
                    scan_results[zone] = []
                scan_results[zone].append(cache_data['module_info'])
            
            self.logger.info("ğŸ“¦ ä½¿ç”¨ç¼“å­˜æ‰«æç»“æœ")
            return scan_results
        
        zones = self.discover_zones()
        scan_results = {}
        total_modules = 0
        total_classes = 0
        total_discoverable = 0
        total_errors = 0
        
        # å¹¶è¡Œæ‰«æ
        if self.enable_parallel_scan and len(zones) > 1:
            scan_results = self._parallel_scan(zones)
        else:
            # ä¸²è¡Œæ‰«æ
            for zone in zones:
                self.logger.info(f"ğŸ“ æ‰«æåŒºåŸŸ: {zone}")
                zone_results = self._scan_zone_modules(zone)
                
                if zone_results:
                    scan_results[zone] = zone_results
                    total_modules += len(zone_results)
                    
                    # ç»Ÿè®¡
                    for module_info in zone_results:
                        total_classes += len(module_info.classes)
                        total_discoverable += sum(1 for cls in module_info.classes if cls.is_discoverable)
                        if not module_info.analysis_success:
                            total_errors += 1
        
        # æ›´æ–°ç»Ÿè®¡
        scan_time = time.time() - start_time
        self._update_scan_stats(total_modules, total_classes, total_discoverable, total_errors, scan_time)
        self._last_scan_time = time.time()
        
        self.logger.info(f"ğŸ“¦ æ·±åº¦æ‰«æå®Œæˆ: æ€»å…± {total_modules} ä¸ªæ¨¡å—, {total_classes} ä¸ªç±», {total_discoverable} ä¸ªå¯å‘ç°ç±»")
        self.logger.info(f"â±ï¸ æ‰«æè€—æ—¶: {scan_time:.2f} ç§’")
        
        return scan_results
    
    def _parallel_scan(self, zones: List[str]) -> Dict[str, List[ModuleInfo]]:
        """å¹¶è¡Œæ‰«æå¤šä¸ªåŒºåŸŸ"""
        scan_results = {}
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰åŒºåŸŸæ‰«æä»»åŠ¡
            future_to_zone = {
                executor.submit(self._scan_zone_modules, zone): zone 
                for zone in zones
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_zone.keys()):
                zone = future_to_zone[future]
                try:
                    zone_results = future.result(timeout=self.scan_timeout)
                    if zone_results:
                        scan_results[zone] = zone_results
                        self.logger.info(f"âœ… {zone}åŒº: å‘ç° {len(zone_results)} ä¸ªæ¨¡å—")
                except Exception as e:
                    self.logger.error(f"âŒ æ‰«æåŒºåŸŸ {zone} å¤±è´¥: {e}")
        
        return scan_results
    
    def _scan_zone_modules(self, zone: str) -> List[ModuleInfo]:
        """æ‰«æå•ä¸ªåŒºåŸŸçš„æ‰€æœ‰æ¨¡å—"""
        zone_modules = self.scan_zone(zone)
        zone_results = []
        
        for module_name in zone_modules:
            self.logger.debug(f"  ğŸ” åˆ†ææ¨¡å—: {module_name}")
            module_info = self.analyze_module(zone, module_name)
            zone_results.append(module_info)
            
            # è®°å½•å‘ç°çš„å¯å‘ç°ç±»
            discoverable_classes = [cls for cls in module_info.classes if cls.is_discoverable]
            if discoverable_classes:
                class_names = [cls.name for cls in discoverable_classes]
                self.logger.info(f"    ğŸ¯ å‘ç°å¯å‘ç°ç±»: {', '.join(class_names)}")
            
            if not module_info.analysis_success:
                self.logger.warning(f"    âš ï¸ æ¨¡å—åˆ†æå¤±è´¥: {module_info.error}")
        
        return zone_results
    
    def _update_scan_stats(self, modules: int, classes: int, discoverable: int, errors: int, scan_time: float):
        """æ›´æ–°æ‰«æç»Ÿè®¡"""
        self._scan_stats['total_scans'] += 1
        self._scan_stats['total_modules'] += modules
        self._scan_stats['total_classes'] += classes
        self._scan_stats['total_discoverable'] += discoverable
        self._scan_stats['total_errors'] += errors
        self._scan_stats['total_scan_time'] += scan_time
    
    def get_discoverable_classes(self, scan_results: Dict[str, List[ModuleInfo]] = None) -> List[ClassInfo]:
        """è·å–æ‰€æœ‰å¯å‘ç°ç±»"""
        if scan_results is None:
            scan_results = self.deep_scan()
        
        discoverable_classes = []
        for zone_modules in scan_results.values():
            for module_info in zone_modules:
                discoverable_classes.extend([
                    cls for cls in module_info.classes 
                    if cls.is_discoverable
                ])
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        discoverable_classes.sort(key=lambda x: x.priority, reverse=True)
        return discoverable_classes
    
    def generate_discovery_report(self, scan_results: Dict[str, List[ModuleInfo]] = None) -> Dict[str, Any]:
        """ç”Ÿæˆå‘ç°æŠ¥å‘Š"""
        if scan_results is None:
            scan_results = self.deep_scan()
        
        discoverable_classes = self.get_discoverable_classes(scan_results)
        
        report = {
            'scan_timestamp': time.time(),
            'total_zones': len(scan_results),
            'total_modules': sum(len(modules) for modules in scan_results.values()),
            'total_classes': sum(len(module_info.classes) for modules in scan_results.values() for module_info in modules),
            'total_discoverable': len(discoverable_classes),
            'zones': {},
            'discoverable_by_zone': {},
            'performance': {
                'cache_enabled': self.cache_enabled,
                'cache_size': len(self._scan_cache),
                'last_scan_time': self._last_scan_time,
                'scan_stats': self._scan_stats.copy()
            }
        }
        
        # æŒ‰åŒºåŸŸç»Ÿè®¡
        for zone, modules in scan_results.items():
            zone_classes = sum(len(module_info.classes) for module_info in modules)
            zone_discoverable = sum(
                1 for module_info in modules 
                for cls in module_info.classes 
                if cls.is_discoverable
            )
            
            report['zones'][zone] = {
                'modules': len(modules),
                'classes': zone_classes,
                'discoverable': zone_discoverable
            }
            
            # å¯å‘ç°ç±»è¯¦æƒ…
            zone_discoverable_classes = [
                cls for module_info in modules 
                for cls in module_info.classes 
                if cls.is_discoverable
            ]
            
            report['discoverable_by_zone'][zone] = [
                {
                    'name': cls.name,
                    'module': cls.module,
                    'priority': cls.priority,
                    'service_type': cls.service_type
                }
                for cls in zone_discoverable_classes
            ]
        
        return report
    
    def clear_cache(self):
        """æ¸…ç©ºæ‰«æç¼“å­˜"""
        self._scan_cache.clear()
        self.logger.info("æ‰«æç¼“å­˜å·²æ¸…ç©º")
    
    def get_cache_info(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ä¿¡æ¯"""
        return {
            'enabled': self.cache_enabled,
            'size': len(self._scan_cache),
            'ttl': self._cache_ttl,
            'last_scan': self._last_scan_time,
            'memory_usage': sum(
                sys.getsizeof(cache_data) + sys.getsizeof(key)
                for key, cache_data in self._scan_cache.items()
            )
        }
    
    def validate_module(self, zone: str, module_name: str) -> Dict[str, Any]:
        """éªŒè¯æ¨¡å—çš„å®Œæ•´æ€§å’Œå¯ç”¨æ€§"""
        module_info = self.analyze_module(zone, module_name)
        
        validation_result = {
            'module': f"{zone}.{module_name}",
            'file_exists': Path(module_info.file_path).exists(),
            'analysis_success': module_info.analysis_success,
            'has_classes': len(module_info.classes) > 0,
            'has_discoverable': any(cls.is_discoverable for cls in module_info.classes),
            'file_size_valid': module_info.file_size <= self.max_file_size,
            'imports_valid': True,  # ç®€åŒ–éªŒè¯
            'errors': []
        }
        
        if not module_info.analysis_success:
            validation_result['errors'].append(f"åˆ†æå¤±è´¥: {module_info.error}")
        
        if module_info.file_size > self.max_file_size:
            validation_result['errors'].append(f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶: {module_info.file_size} > {self.max_file_size}")
        
        validation_result['is_valid'] = (
            validation_result['file_exists'] and
            validation_result['analysis_success'] and
            validation_result['file_size_valid'] and
            len(validation_result['errors']) == 0
        )
        
        return validation_result
# æ‰«æå™¨æ„å»ºå™¨
class ScannerBuilder:
    """æ‰«æå™¨æ„å»ºå™¨ï¼Œç”¨äºé…ç½®å’Œåˆ›å»ºæ‰«æå™¨"""
    
    def __init__(self):
        self._config = {
            'ignore_dirs': {'__pycache__', '.git', 'config', 'logs', 'tests', 'temp', 'backup', 'data'},
            'ignore_files': {'__init__.py', 'test_', '_test.py', 'conftest.py'},
            'max_file_size': 10 * 1024 * 1024,
            'analysis_level': 'detailed',
            'enable_parallel_scan': True,
            'max_workers': 8,
            'cache_enabled': True,
            'cache_ttl': 600,
            'scan_timeout': 60
        }
    
    def set_analysis_level(self, level: AnalysisLevel) -> 'ScannerBuilder':
        """è®¾ç½®åˆ†æçº§åˆ«"""
        self._config['analysis_level'] = level.value
        return self
    
    def set_parallel_scan(self, enabled: bool, max_workers: int = None) -> 'ScannerBuilder':
        """è®¾ç½®å¹¶è¡Œæ‰«æ"""
        self._config['enable_parallel_scan'] = enabled
        if max_workers is not None:
            self._config['max_workers'] = max_workers
        return self
    
    def set_cache(self, enabled: bool, ttl: int = None) -> 'ScannerBuilder':
        """è®¾ç½®ç¼“å­˜"""
        self._config['cache_enabled'] = enabled
        if ttl is not None:
            self._config['cache_ttl'] = ttl
        return self
    
    def add_ignore_dirs(self, *dirs: str) -> 'ScannerBuilder':
        """æ·»åŠ å¿½ç•¥ç›®å½•"""
        self._config['ignore_dirs'].update(dirs)
        return self
    
    def add_ignore_files(self, *files: str) -> 'ScannerBuilder':
        """æ·»åŠ å¿½ç•¥æ–‡ä»¶"""
        self._config['ignore_files'].update(files)
        return self
    
    def build(self, aoo_root: str, config_manager=None) -> ModuleScanner:
        """æ„å»ºæ‰«æå™¨å®ä¾‹"""
        scanner = ModuleScanner(aoo_root, config_manager)
        
        # åº”ç”¨é…ç½®
        for key, value in self._config.items():
            if hasattr(scanner, key):
                setattr(scanner, key, value)
        
        return scanner


class ScanningError(Exception):
    """æ‰«æé”™è¯¯å¼‚å¸¸"""
    pass


class ModuleAnalysisError(ScanningError):
    """æ¨¡å—åˆ†æé”™è¯¯å¼‚å¸¸"""
    pass