"""
T9æ•°æ®çŠ¶æ€èšåˆå™¨æ¨¡å— - ç»Ÿä¸€å¯¼å‡ºæ¥å£

è¯¥æ¨¡å—æä¾›äº†å®Œæ•´çš„æ•°æ®çŠ¶æ€èšåˆå’Œç›‘æ§åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- æ•°æ®æ¨¡å—çŠ¶æ€æ”¶é›†å’Œç›‘æ§
- æ•°æ®è´¨é‡æŒ‡æ ‡èšåˆå’Œåˆ†æ
- æ•°æ®ä½¿ç”¨ç»Ÿè®¡å’Œæ€§èƒ½ç›‘æ§
- æ•°æ®å¥åº·åº¦è¯„ä¼°å’Œå‘Šè­¦ç®¡ç†
- æ•°æ®èµ„æºæ¶ˆè€—ç›‘æ§å’ŒçŠ¶æ€å˜æ›´è·Ÿè¸ª
- æ•°æ®çŠ¶æ€æŠ¥å‘Šç”Ÿæˆå’Œå¯¼å‡ºåŠŸèƒ½

Author: T9ç³»ç»Ÿå¼€å‘å›¢é˜Ÿ
Date: 2025-11-13
Version: 1.0.0
License: MIT
"""

# ç‰ˆæœ¬ä¿¡æ¯
__version__ = "1.0.0"
__author__ = "T9ç³»ç»Ÿå¼€å‘å›¢é˜Ÿ"
__license__ = "MIT"
__email__ = "dev@T9-system.com"
__description__ = "T9æ•°æ®çŠ¶æ€èšåˆå™¨ - å®Œæ•´çš„æ•°æ®ç›‘æ§å’ŒçŠ¶æ€ç®¡ç†ç³»ç»Ÿ"

# ç±»å‹å¯¼å…¥
from typing import Dict, Any, List, Optional, Union, Tuple, Callable

# æ ¸å¿ƒç±»å¯¼å‡º
from .DataStateAggregator import (
    # æšä¸¾ç±»
    DataStatus,
    DataQualityLevel,
    AlertLevel,
    
    # æ•°æ®ç»“æ„ç±»
    DataModuleInfo,
    DataQualityMetrics,
    DataUsageStats,
    DataPerformanceMetrics,
    ResourceConsumption,
    StateChangeEvent,
    DataHealthScore,
    Alert,
    
    # æ”¶é›†å™¨ç±»
    DataModuleCollector,
    MockDataModuleCollector,
    
    # ç®¡ç†å™¨ç±»
    AlertManager,
    
    # ä¸»è¦åŠŸèƒ½ç±»
    DataStateAggregator,
    
    # æµ‹è¯•ç±»
    TestDataStateAggregator
)

# ç‰ˆæœ¬å…ƒæ•°æ®
__all__ = [
    # ç‰ˆæœ¬ä¿¡æ¯
    "__version__",
    "__author__", 
    "__license__",
    "__email__",
    "__description__",
    
    # æšä¸¾ç±»
    "DataStatus",
    "DataQualityLevel", 
    "AlertLevel",
    
    # æ•°æ®ç±»
    "DataModuleInfo",
    "DataQualityMetrics",
    "DataUsageStats", 
    "DataPerformanceMetrics",
    "ResourceConsumption",
    "StateChangeEvent",
    "DataHealthScore",
    "Alert",
    
    # æ ¸å¿ƒåŠŸèƒ½ç±»
    "DataModuleCollector",
    "MockDataModuleCollector",
    "AlertManager",
    "DataStateAggregator",
    "TestDataStateAggregator",
    
    # ä¾¿åˆ©å‡½æ•°
    "create_aggregator",
    "quick_start_demo",
    "generate_sample_data",
    "get_system_health",
    "export_monitoring_data"
]

# =============================================================================
# é»˜è®¤é…ç½®å¸¸é‡
# =============================================================================

# é»˜è®¤é…ç½®
DEFAULT_CONFIG = {
    # æ•°æ®æ”¶é›†é…ç½®
    "collection_interval": 60,  # æ•°æ®æ”¶é›†é—´éš”ï¼ˆç§’ï¼‰
    "max_history_records": 1000,  # æœ€å¤§å†å²è®°å½•æ•°
    "alert_retention_days": 30,  # å‘Šè­¦ä¿ç•™å¤©æ•°
    
    # æ€§èƒ½é…ç½®
    "max_concurrent_collectors": 10,  # æœ€å¤§å¹¶å‘æ”¶é›†å™¨æ•°é‡
    "collection_timeout": 30,  # å•æ¬¡æ”¶é›†è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    
    # å‘Šè­¦é…ç½®
    "cpu_warning_threshold": 80.0,  # CPUå‘Šè­¦é˜ˆå€¼
    "memory_warning_threshold": 90.0,  # å†…å­˜å‘Šè­¦é˜ˆå€¼
    "error_rate_threshold": 5.0,  # é”™è¯¯ç‡å‘Šè­¦é˜ˆå€¼
    "quality_score_threshold": 0.7,  # è´¨é‡åˆ†æ•°å‘Šè­¦é˜ˆå€¼
    
    # æŠ¥å‘Šé…ç½®
    "report_formats": ["json", "text", "html"],  # æ”¯æŒçš„æŠ¥å‘Šæ ¼å¼
    "include_metadata": True,  # æŠ¥å‘Šä¸­åŒ…å«å…ƒæ•°æ®
    "max_recent_events": 10,  # æŠ¥å‘Šä¸­åŒ…å«çš„æœ€å¤§æœ€è¿‘äº‹ä»¶æ•°
}

# å¥åº·åº¦é˜ˆå€¼é…ç½®
HEALTH_THRESHOLDS = {
    "excellent": 90.0,  # ä¼˜ç§€é˜ˆå€¼
    "good": 75.0,       # è‰¯å¥½é˜ˆå€¼  
    "fair": 60.0,       # ä¸€èˆ¬é˜ˆå€¼
    "poor": 40.0,       # è¾ƒå·®é˜ˆå€¼
    "unacceptable": 0.0 # ä¸å¯æ¥å—é˜ˆå€¼
}

# èµ„æºä½¿ç”¨é˜ˆå€¼
RESOURCE_THRESHOLDS = {
    "cpu_cores": {"max": 16.0, "warning": 12.0},
    "memory_mb": {"max": 16384.0, "warning": 12288.0},
    "disk_gb": {"max": 1000.0, "warning": 800.0},
    "network_mbps": {"max": 1000.0, "warning": 800.0},
    "storage_gb": {"max": 5000.0, "warning": 4000.0},
}

# æ€§èƒ½æŒ‡æ ‡é…ç½®
PERFORMANCE_CONFIG = {
    "latency_percentiles": [50, 95, 99],  # å»¶è¿Ÿç™¾åˆ†ä½æ•°
    "throughput_unit": "qps",  # ååé‡å•ä½
    "error_rate_unit": "percent",  # é”™è¯¯ç‡å•ä½
    "availability_target": 99.9,  # å¯ç”¨æ€§ç›®æ ‡ï¼ˆç™¾åˆ†æ¯”ï¼‰
}

# å‘Šè­¦é…ç½®
ALERT_CONFIG = {
    "auto_escalation": True,  # è‡ªåŠ¨å‡çº§å‘Šè­¦
    "escalation_timeout": 300,  # å‡çº§è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    "notification_channels": ["log", "email"],  # é€šçŸ¥æ¸ é“
    "rate_limiting": {
        "max_alerts_per_hour": 100,
        "cooldown_period": 60  # å†·å´æœŸï¼ˆç§’ï¼‰
    }
}

# =============================================================================
# å¸¸é‡å®šä¹‰
# =============================================================================

# çŠ¶æ€å¸¸é‡
STATUS_LABELS = {
    "healthy": "å¥åº·",
    "warning": "è­¦å‘Š", 
    "critical": "ä¸¥é‡",
    "unknown": "æœªçŸ¥",
    "maintenance": "ç»´æŠ¤ä¸­"
}

# è´¨é‡ç­‰çº§æ ‡ç­¾
QUALITY_LABELS = {
    "excellent": "ä¼˜ç§€",
    "good": "è‰¯å¥½",
    "fair": "ä¸€èˆ¬", 
    "poor": "è¾ƒå·®",
    "unacceptable": "ä¸å¯æ¥å—"
}

# å‘Šè­¦çº§åˆ«æ ‡ç­¾
ALERT_LABELS = {
    "info": "ä¿¡æ¯",
    "warning": "è­¦å‘Š",
    "error": "é”™è¯¯", 
    "critical": "ä¸¥é‡"
}

# æ¨¡å—ç±»å‹æ ‡ç­¾
MODULE_TYPE_LABELS = {
    "user_data": "ç”¨æˆ·æ•°æ®",
    "order_data": "è®¢å•æ•°æ®",
    "product_data": "äº§å“æ•°æ®",
    "transaction_data": "äº¤æ˜“æ•°æ®",
    "log_data": "æ—¥å¿—æ•°æ®",
    "cache_data": "ç¼“å­˜æ•°æ®"
}

# å•ä½å¸¸é‡
UNITS = {
    "cpu": "%",
    "memory": "MB", 
    "disk": "GB",
    "network": "Mbps",
    "storage": "GB",
    "latency": "ms",
    "throughput": "QPS",
    "cost": "å…ƒ/å°æ—¶"
}

# æ”¶é›†å™¨ç±»å‹
COLLECTOR_TYPES = {
    "mock": "æ¨¡æ‹Ÿæ”¶é›†å™¨",
    "prometheus": "Prometheusæ”¶é›†å™¨",
    "statsd": "StatsDæ”¶é›†å™¨",
    "custom": "è‡ªå®šä¹‰æ”¶é›†å™¨"
}

# =============================================================================
# ä¾¿åˆ©å‡½æ•°
# =============================================================================

def create_aggregator(
    collector_type: str = "mock",
    collection_interval: int = DEFAULT_CONFIG["collection_interval"],
    **kwargs
) -> DataStateAggregator:
    """
    åˆ›å»ºæ•°æ®çŠ¶æ€èšåˆå™¨å®ä¾‹çš„ä¾¿åˆ©å‡½æ•°
    
    Args:
        collector_type: æ”¶é›†å™¨ç±»å‹ ("mock", "prometheus", "statsd", "custom")
        collection_interval: æ•°æ®æ”¶é›†é—´éš”ï¼ˆç§’ï¼‰
        **kwargs: å…¶ä»–åˆå§‹åŒ–å‚æ•°
        
    Returns:
        DataStateAggregator: æ•°æ®çŠ¶æ€èšåˆå™¨å®ä¾‹
        
    Example:
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®èšåˆå™¨
        aggregator = create_aggregator("mock", collection_interval=30)
        
        # åˆ›å»ºè‡ªå®šä¹‰æ”¶é›†å™¨èšåˆå™¨
        custom_collector = MyCustomCollector()
        aggregator = create_aggregator("custom", collector=custom_collector)
    """
    from .DataStateAggregator import MockDataModuleCollector, DataModuleCollector
    
    if collector_type == "mock":
        collector = MockDataModuleCollector()
        return DataStateAggregator(collector=collector, collection_interval=collection_interval)
    elif collector_type == "custom":
        collector = kwargs.get("collector")
        if not collector or not isinstance(collector, DataModuleCollector):
            raise ValueError("è‡ªå®šä¹‰æ”¶é›†å™¨å¿…é¡»æ˜¯DataModuleCollectorçš„å®ä¾‹")
        return DataStateAggregator(collector=collector, collection_interval=collection_interval)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ”¶é›†å™¨ç±»å‹: {collector_type}")


async def quick_start_demo(
    duration: int = 10,
    collection_interval: int = 3
) -> None:
    """
    å¿«é€Ÿå¼€å§‹æ¼”ç¤ºå‡½æ•°
    
    Args:
        duration: æ¼”ç¤ºè¿è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
        collection_interval: æ•°æ®æ”¶é›†é—´éš”ï¼ˆç§’ï¼‰
        
    Example:
        # è¿è¡Œ10ç§’æ¼”ç¤º
        await quick_start_demo(duration=10)
    """
    from .DataStateAggregator import DataStateAggregator, MockDataModuleCollector
    
    print("ğŸš€ T9æ•°æ®çŠ¶æ€èšåˆå™¨å¿«é€Ÿæ¼”ç¤º")
    print("=" * 40)
    
    # åˆ›å»ºèšåˆå™¨
    collector = MockDataModuleCollector()
    aggregator = DataStateAggregator(collector=collector, collection_interval=collection_interval)
    
    try:
        # å¯åŠ¨æ•°æ®æ”¶é›†
        print("ğŸ“Š å¯åŠ¨æ•°æ®æ”¶é›†...")
        await aggregator.start_collection()
        
        # è¿è¡ŒæŒ‡å®šæ—¶é—´
        print(f"â±ï¸  è¿è¡Œæ•°æ®æ”¶é›†ï¼ˆ{duration}ç§’ï¼‰...")
        await asyncio.sleep(duration)
        
        # ç”Ÿæˆå¹¶æ˜¾ç¤ºæŠ¥å‘Š
        print("\nğŸ“ˆ ç”Ÿæˆç³»ç»ŸçŠ¶æ€æŠ¥å‘Š...")
        report = aggregator.generate_status_report("text")
        print(report)
        
        # æ˜¾ç¤ºç³»ç»Ÿæ¦‚è§ˆ
        print("\nğŸ“‹ ç³»ç»Ÿæ¦‚è§ˆä¿¡æ¯:")
        overview = aggregator.get_system_overview()
        for key, value in overview.items():
            print(f"  â€¢ {key}: {value}")
        
        # æ˜¾ç¤ºæ´»è·ƒå‘Šè­¦
        active_alerts = aggregator.alert_manager.get_active_alerts()
        print(f"\nğŸš¨ æ´»è·ƒå‘Šè­¦æ•°é‡: {len(active_alerts)}")
        for alert in active_alerts:
            print(f"  â€¢ [{ALERT_LABELS[alert.alert_level.value]}] {alert.title}")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        # åœæ­¢æ•°æ®æ”¶é›†
        print("\nâ¹ï¸  åœæ­¢æ•°æ®æ”¶é›†...")
        await aggregator.stop_collection()
        print("âœ… æ¼”ç¤ºå®Œæˆ!")


def generate_sample_data(
    module_count: int = 3,
    include_metrics: bool = True
) -> Dict[str, Any]:
    """
    ç”Ÿæˆç¤ºä¾‹æ•°æ®
    
    Args:
        module_count: æ¨¡å—æ•°é‡
        include_metrics: æ˜¯å¦åŒ…å«æŒ‡æ ‡æ•°æ®
        
    Returns:
        Dict: ç¤ºä¾‹æ•°æ®å­—å…¸
    """
    from .DataStateAggregator import (
        DataModuleInfo, DataStatus, DataQualityMetrics, DataPerformanceMetrics,
        ResourceConsumption, DataHealthScore
    )
    from datetime import datetime
    import random
    
    modules = []
    for i in range(module_count):
        module = DataModuleInfo(
            module_id=f"module_{i+1}",
            module_name=f"ç¤ºä¾‹æ¨¡å—_{i+1}",
            module_type=f"type_{i+1}",
            status=random.choice(list(DataStatus)),
            last_updated=datetime.now(),
            metadata={"description": f"è¿™æ˜¯ç¤ºä¾‹æ¨¡å— {i+1}"}
        )
        modules.append(module)
    
    sample_data = {
        "modules": [m.__dict__ for m in modules],
        "timestamp": datetime.now().isoformat(),
        "collection_interval": DEFAULT_CONFIG["collection_interval"],
    }
    
    if include_metrics:
        # æ·»åŠ ç¤ºä¾‹æŒ‡æ ‡
        for module in modules:
            quality = DataQualityMetrics(
                completeness=random.uniform(0.7, 1.0),
                accuracy=random.uniform(0.8, 1.0),
                consistency=random.uniform(0.7, 0.95),
                timeliness=random.uniform(0.6, 0.9),
                validity=random.uniform(0.75, 1.0)
            )
            
            performance = DataPerformanceMetrics(
                cpu_usage=random.uniform(10, 90),
                memory_usage=random.uniform(20, 95),
                disk_io=random.uniform(5, 50),
                network_io=random.uniform(1, 30),
                query_latency_p50=random.uniform(10, 100),
                query_latency_p95=random.uniform(50, 300),
                query_latency_p99=random.uniform(100, 600),
                throughput_qps=random.uniform(100, 2000),
                error_rate=random.uniform(0, 10)
            )
            
            resource = ResourceConsumption(
                cpu_cores=random.uniform(0.5, 8.0),
                memory_mb=random.uniform(512, 8192),
                disk_gb=random.uniform(10, 500),
                network_mbps=random.uniform(1, 200),
                storage_gb=random.uniform(50, 2000),
                cost_per_hour=random.uniform(0.1, 10.0)
            )
            
            health = DataHealthScore(
                overall_score=random.uniform(60, 95),
                availability=random.uniform(80, 100),
                performance=random.uniform(70, 95),
                quality=quality.overall_score * 100,
                security=random.uniform(80, 95),
                compliance=random.uniform(85, 100)
            )
            
            module.metrics = {
                "quality": quality.__dict__,
                "performance": performance.__dict__, 
                "resource": resource.__dict__,
                "health": health.__dict__
            }
    
    return sample_data


def get_system_health(aggregator: DataStateAggregator) -> Dict[str, Any]:
    """
    è·å–ç³»ç»Ÿå¥åº·çŠ¶å†µæ‘˜è¦
    
    Args:
        aggregator: æ•°æ®çŠ¶æ€èšåˆå™¨å®ä¾‹
        
    Returns:
        Dict: ç³»ç»Ÿå¥åº·çŠ¶å†µæ‘˜è¦
    """
    with aggregator._lock:
        overview = aggregator.get_system_overview()
        active_alerts = aggregator.alert_manager.get_active_alerts()
        
        # è®¡ç®—å¥åº·ç­‰çº§
        total_modules = overview["total_modules"]
        if total_modules == 0:
            health_level = "unknown"
        else:
            critical_count = overview["modules_by_status"].get("critical", 0)
            warning_count = overview["modules_by_status"].get("warning", 0)
            
            if critical_count > 0:
                health_level = "critical"
            elif warning_count > total_modules * 0.3:
                health_level = "warning"
            else:
                health_level = "healthy"
        
        return {
            "health_level": health_level,
            "health_score": 100 - (critical_count * 20 + warning_count * 10),
            "total_modules": total_modules,
            "healthy_modules": overview["modules_by_status"].get("healthy", 0),
            "warning_modules": overview["modules_by_status"].get("warning", 0),
            "critical_modules": overview["modules_by_status"].get("critical", 0),
            "active_alerts": len(active_alerts),
            "average_quality": overview["average_quality_score"],
            "collection_success_rate": (
                overview["collection_stats"]["successful_collections"] / 
                max(overview["collection_stats"]["total_collections"], 1) * 100
            )
        }


def export_monitoring_data(
    aggregator: DataStateAggregator,
    format_type: str = "json",
    include_history: bool = True
) -> str:
    """
    å¯¼å‡ºç›‘æ§æ•°æ®
    
    Args:
        aggregator: æ•°æ®çŠ¶æ€èšåˆå™¨å®ä¾‹
        format_type: å¯¼å‡ºæ ¼å¼ ("json", "csv")
        include_history: æ˜¯å¦åŒ…å«å†å²æ•°æ®
        
    Returns:
        str: å¯¼å‡ºçš„æ•°æ®å­—ç¬¦ä¸²
    """
    if format_type.lower() == "json":
        return aggregator.export_data()
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {format_type}")


# =============================================================================
# å¿«é€Ÿå…¥é—¨æŒ‡å—
# =============================================================================

def print_quick_start_guide():
    """æ‰“å°å¿«é€Ÿå…¥é—¨æŒ‡å—"""
    guide = """
ğŸ¯ T9æ•°æ®çŠ¶æ€èšåˆå™¨ - å¿«é€Ÿå…¥é—¨æŒ‡å—
=======================================

ğŸ“š åŸºæœ¬æ¦‚å¿µ:
-----------
â€¢ DataStateAggregator: æ ¸å¿ƒèšåˆå™¨ç±»ï¼Œè´Ÿè´£æ•°æ®æ”¶é›†å’Œåˆ†æ
â€¢ DataModuleCollector: æ•°æ®æ”¶é›†å™¨æŠ½è±¡åŸºç±»
â€¢ MockDataModuleCollector: æ¨¡æ‹Ÿæ•°æ®æ”¶é›†å™¨å®ç°
â€¢ AlertManager: å‘Šè­¦ç®¡ç†å™¨
â€¢ DataStatus: æ•°æ®çŠ¶æ€æšä¸¾ (healthy, warning, critical, unknown, maintenance)
â€¢ DataQualityLevel: æ•°æ®è´¨é‡ç­‰çº§ (excellent, good, fair, poor, unacceptable)

ğŸš€ å¿«é€Ÿå¼€å§‹:
-----------
1. åˆ›å»ºèšåˆå™¨å®ä¾‹:
   from T9 import create_aggregator, DataStateAggregator
   
   # ä½¿ç”¨é»˜è®¤é…ç½®
   aggregator = create_aggregator("mock")
   
   # è‡ªå®šä¹‰é…ç½®
   aggregator = DataStateAggregator(collection_interval=30)

2. å¯åŠ¨æ•°æ®æ”¶é›†:
   import asyncio
   
   async def main():
       await aggregator.start_collection()
       # ... ç­‰å¾…æ•°æ®æ”¶é›†
       await aggregator.stop_collection()
   
   asyncio.run(main())

3. ç”ŸæˆçŠ¶æ€æŠ¥å‘Š:
   # JSONæ ¼å¼æŠ¥å‘Š
   json_report = aggregator.generate_status_report("json")
   
   # æ–‡æœ¬æ ¼å¼æŠ¥å‘Š  
   text_report = aggregator.generate_status_report("text")
   
   # HTMLæ ¼å¼æŠ¥å‘Š
   html_report = aggregator.generate_status_report("html")

4. è·å–ç³»ç»Ÿä¿¡æ¯:
   # è·å–ç³»ç»Ÿæ¦‚è§ˆ
   overview = aggregator.get_system_overview()
   
   # è·å–æ¨¡å—è¯¦ç»†ä¿¡æ¯
   module_info = aggregator.get_module_status("module_1")
   
   # è·å–ç³»ç»Ÿå¥åº·çŠ¶å†µ
   health = get_system_health(aggregator)

5. å¤„ç†å‘Šè­¦:
   # è·å–æ´»è·ƒå‘Šè­¦
   active_alerts = aggregator.alert_manager.get_active_alerts()
   
   # åˆ›å»ºè‡ªå®šä¹‰å‘Šè­¦
   alert = aggregator.alert_manager.create_alert(
       AlertLevel.WARNING,
       "è‡ªå®šä¹‰å‘Šè­¦æ ‡é¢˜",
       "å‘Šè­¦æè¿°å†…å®¹",
       "module_1"
   )
   
   # è§£å†³å‘Šè­¦
   aggregator.alert_manager.resolve_alert(alert.alert_id)

6. å¯¼å‡ºæ•°æ®:
   # å¯¼å‡ºæ‰€æœ‰æ•°æ®
   export_data = aggregator.export_data()
   
   # ä¾¿åˆ©å‡½æ•°å¯¼å‡º
   exported_data = export_monitoring_data(aggregator, "json")

ğŸ’¡ é«˜çº§ç”¨æ³•:
-----------
â€¢ è‡ªå®šä¹‰æ•°æ®æ”¶é›†å™¨: ç»§æ‰¿DataModuleCollectorå®ç°è‡ªå®šä¹‰æ”¶é›†é€»è¾‘
â€¢ è‡ªå®šä¹‰å‘Šè­¦å¤„ç†å™¨: ä½¿ç”¨AlertManager.add_alert_handler()æ·»åŠ å¤„ç†å™¨
â€¢ æ‰¹é‡æ•°æ®å¯¼å‡º: ä½¿ç”¨export_monitoring_data()æ‰¹é‡å¯¼å‡ºç›‘æ§æ•°æ®
â€¢ å¥åº·åº¦è¯„ä¼°: ä½¿ç”¨DataHealthScore.get_health_level()è·å–å¥åº·ç­‰çº§
â€¢ æ€§èƒ½ç›‘æ§: ç›‘æ§CPUã€å†…å­˜ã€ç£ç›˜ã€ç½‘ç»œç­‰èµ„æºä½¿ç”¨æƒ…å†µ
â€¢ è´¨é‡è¯„ä¼°: è¯„ä¼°æ•°æ®å®Œæ•´æ€§ã€å‡†ç¡®æ€§ã€ä¸€è‡´æ€§ã€åŠæ—¶æ€§ã€æœ‰æ•ˆæ€§

ğŸ”§ é…ç½®é€‰é¡¹:
-----------
â€¢ collection_interval: æ•°æ®æ”¶é›†é—´éš”ï¼ˆé»˜è®¤60ç§’ï¼‰
â€¢ max_history_records: æœ€å¤§å†å²è®°å½•æ•°ï¼ˆé»˜è®¤1000æ¡ï¼‰
â€¢ alert_retention_days: å‘Šè­¦ä¿ç•™å¤©æ•°ï¼ˆé»˜è®¤30å¤©ï¼‰
â€¢ cpu_warning_threshold: CPUå‘Šè­¦é˜ˆå€¼ï¼ˆé»˜è®¤80%ï¼‰
â€¢ memory_warning_threshold: å†…å­˜å‘Šè­¦é˜ˆå€¼ï¼ˆé»˜è®¤90%ï¼‰
â€¢ error_rate_threshold: é”™è¯¯ç‡å‘Šè­¦é˜ˆå€¼ï¼ˆé»˜è®¤5%ï¼‰

ğŸ“Š ç›‘æ§æŒ‡æ ‡:
-----------
â€¢ æ€§èƒ½æŒ‡æ ‡: CPUä½¿ç”¨ç‡ã€å†…å­˜ä½¿ç”¨ç‡ã€ç£ç›˜IOã€ç½‘ç»œIOã€æŸ¥è¯¢å»¶è¿Ÿã€ååé‡ã€é”™è¯¯ç‡
â€¢ è´¨é‡æŒ‡æ ‡: å®Œæ•´æ€§ã€å‡†ç¡®æ€§ã€ä¸€è‡´æ€§ã€åŠæ—¶æ€§ã€æœ‰æ•ˆæ€§
â€¢ ä½¿ç”¨ç»Ÿè®¡: è¯»æ“ä½œã€å†™æ“ä½œã€æŸ¥è¯¢æ¬¡æ•°ã€ç‹¬ç‰¹ç”¨æˆ·ã€å“åº”æ—¶é—´ã€å¹¶å‘ç”¨æˆ·ã€æ•°æ®é‡
â€¢ èµ„æºæ¶ˆè€—: CPUæ ¸å¿ƒã€å†…å­˜ã€ç£ç›˜ã€ç½‘ç»œã€å­˜å‚¨ã€æˆæœ¬
â€¢ å¥åº·è¯„åˆ†: å¯ç”¨æ€§ã€æ€§èƒ½ã€è´¨é‡ã€å®‰å…¨æ€§ã€åˆè§„æ€§

ğŸ“ ç¤ºä¾‹ä»£ç :
-----------
# åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹
from T9 import create_aggregator
import asyncio

async def example():
    # åˆ›å»ºèšåˆå™¨
    aggregator = create_aggregator("mock", collection_interval=5)
    
    # å¯åŠ¨æ”¶é›†
    await aggregator.start_collection()
    
    # è¿è¡Œä¸€æ®µæ—¶é—´
    await asyncio.sleep(10)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = aggregator.generate_status_report("text")
    print(report)
    
    # åœæ­¢æ”¶é›†
    await aggregator.stop_collection()

# è¿è¡Œç¤ºä¾‹
asyncio.run(example())

# å¿«é€Ÿæ¼”ç¤º
from T9 import quick_start_demo
await quick_start_demo(duration=15)

â“ å¸¸è§é—®é¢˜:
-----------
Q: å¦‚ä½•æ·»åŠ è‡ªå®šä¹‰å‘Šè­¦ï¼Ÿ
A: ä½¿ç”¨aggregator.alert_manager.create_alert()æ–¹æ³•

Q: å¦‚ä½•ç›‘æ§å¤šä¸ªæ¨¡å—ï¼Ÿ
A: DataStateAggregatorä¼šè‡ªåŠ¨ç›‘æ§æ‰€æœ‰æ³¨å†Œçš„æ¨¡å—

Q: å¦‚ä½•è‡ªå®šä¹‰æ•°æ®æ”¶é›†å™¨ï¼Ÿ
A: ç»§æ‰¿DataModuleCollectorå¹¶å®ç°æ‰€æœ‰æŠ½è±¡æ–¹æ³•

Q: å¦‚ä½•è°ƒæ•´æ”¶é›†é¢‘ç‡ï¼Ÿ
A: åœ¨åˆ›å»ºèšåˆå™¨æ—¶è®¾ç½®collection_intervalå‚æ•°

ğŸ“ æŠ€æœ¯æ”¯æŒ:
-----------
â€¢ é‚®ç®±: dev@T9-system.com
â€¢ æ–‡æ¡£: https://docs.T9-system.com
â€¢ GitHub: https://github.com/T9-system/monitoring
â€¢ é—®é¢˜åé¦ˆ: https://github.com/T9-system/issues

ğŸ‰ å¼€å§‹ä½¿ç”¨:
-----------
ç°åœ¨æ‚¨å¯ä»¥å¼€å§‹ä½¿ç”¨T9æ•°æ®çŠ¶æ€èšåˆå™¨äº†ï¼
å»ºè®®å…ˆè¿è¡Œquick_start_demo()è¿›è¡Œå¿«é€Ÿä½“éªŒã€‚
"""
    print(guide)


def print_api_reference():
    """æ‰“å°APIå‚è€ƒ"""
    api_doc = """
ğŸ“– T9æ•°æ®çŠ¶æ€èšåˆå™¨ API å‚è€ƒ
============================

ğŸ—ï¸ æ ¸å¿ƒç±»:
---------
â€¢ DataStateAggregator: ä¸»è¦èšåˆå™¨ç±»
â€¢ DataModuleCollector: æ•°æ®æ”¶é›†å™¨åŸºç±»
â€¢ MockDataModuleCollector: æ¨¡æ‹Ÿæ”¶é›†å™¨å®ç°
â€¢ AlertManager: å‘Šè­¦ç®¡ç†å™¨
â€¢ TestDataStateAggregator: æµ‹è¯•ç±»

ğŸ“Š æ•°æ®ç»“æ„:
-----------
â€¢ DataStatus: æ•°æ®çŠ¶æ€æšä¸¾
â€¢ DataQualityLevel: æ•°æ®è´¨é‡ç­‰çº§æšä¸¾
â€¢ AlertLevel: å‘Šè­¦çº§åˆ«æšä¸¾
â€¢ DataModuleInfo: æ¨¡å—ä¿¡æ¯æ•°æ®ç±»
â€¢ DataQualityMetrics: è´¨é‡æŒ‡æ ‡æ•°æ®ç±»
â€¢ DataUsageStats: ä½¿ç”¨ç»Ÿè®¡æ•°æ®ç±»
â€¢ DataPerformanceMetrics: æ€§èƒ½æŒ‡æ ‡æ•°æ®ç±»
â€¢ ResourceConsumption: èµ„æºæ¶ˆè€—æ•°æ®ç±»
â€¢ StateChangeEvent: çŠ¶æ€å˜æ›´äº‹ä»¶æ•°æ®ç±»
â€¢ DataHealthScore: å¥åº·åº¦è¯„åˆ†æ•°æ®ç±»
â€¢ Alert: å‘Šè­¦ä¿¡æ¯æ•°æ®ç±»

ğŸ”§ ä¸»è¦æ–¹æ³•:
-----------
â€¢ start_collection(): å¯åŠ¨æ•°æ®æ”¶é›†
â€¢ stop_collection(): åœæ­¢æ•°æ®æ”¶é›†
â€¢ collect_all_data(): æ”¶é›†æ‰€æœ‰æ•°æ®
â€¢ generate_status_report(): ç”ŸæˆçŠ¶æ€æŠ¥å‘Š
â€¢ get_system_overview(): è·å–ç³»ç»Ÿæ¦‚è§ˆ
â€¢ get_module_status(): è·å–æ¨¡å—çŠ¶æ€
â€¢ export_data(): å¯¼å‡ºæ•°æ®
â€¢ calculate_health_scores(): è®¡ç®—å¥åº·åº¦åˆ†æ•°
â€¢ check_alert_conditions(): æ£€æŸ¥å‘Šè­¦æ¡ä»¶

ğŸ“ è¯¦ç»†æ–‡æ¡£è¯·å‚è€ƒæ¨¡å—æºä»£ç æ³¨é‡Š
"""
    print(api_doc)


# åœ¨æ¨¡å—åŠ è½½æ—¶æ‰“å°æ¬¢è¿ä¿¡æ¯
def _welcome_message():
    """æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯"""
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                  ğŸš€ T9æ•°æ®çŠ¶æ€èšåˆå™¨ {__version__}                          â•‘
â•‘                                                              â•‘
â•‘    å®Œæ•´çš„æ•°æ®ç›‘æ§å’ŒçŠ¶æ€ç®¡ç†ç³»ç»Ÿ                              â•‘
â•‘    ä¸“æ³¨äºæ•°æ®è´¨é‡ã€æ€§èƒ½ç›‘æ§å’Œå¥åº·åº¦è¯„ä¼°                      â•‘
â•‘                                                              â•‘
â•‘    ğŸ“š å¿«é€Ÿå…¥é—¨: print_quick_start_guide()                   â•‘
â•‘    ğŸ“– APIå‚è€ƒ: print_api_reference()                        â•‘
â•‘    ğŸ¯ å¿«é€Ÿæ¼”ç¤º: quick_start_demo()                          â•‘
â•‘    âš™ï¸  åˆ›å»ºå®ä¾‹: create_aggregator()                        â•‘
â•‘                                                              â•‘
â•‘    ğŸ“§ æŠ€æœ¯æ”¯æŒ: dev@T9-system.com                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

# æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
_welcome_message()

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
import asyncio