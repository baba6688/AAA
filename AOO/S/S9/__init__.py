"""
S9çŠ¶æ€èšåˆå™¨æ¨¡å—
================

è¿™æ˜¯SåŒºS9å­æ¨¡å—çš„å®Œæ•´å¯¼å‡ºæ¥å£ï¼Œæä¾›äº†æœåŠ¡çŠ¶æ€èšåˆã€ç›‘æ§ã€åˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆçš„å®Œæ•´åŠŸèƒ½ã€‚

ç‰ˆæœ¬ä¿¡æ¯
--------
- ç‰ˆæœ¬: 1.0.0
- æœ€åæ›´æ–°: 2025-11-13
- ä½œè€…: S9å¼€å‘å›¢é˜Ÿ
- æè¿°: ä¼ä¸šçº§æœåŠ¡çŠ¶æ€èšåˆå’Œç›‘æ§ç³»ç»Ÿ

ä¸»è¦åŠŸèƒ½
--------
- æœåŠ¡çŠ¶æ€æ”¶é›†å’Œèšåˆ
- å®æ—¶ç›‘æ§å’Œé¢„è­¦
- çŠ¶æ€åˆ†æå’Œå¼‚å¸¸æ£€æµ‹
- å†å²æ•°æ®ç®¡ç†
- æŠ¥å‘Šç”Ÿæˆå’Œå¯¼å‡º
- å¯è§†åŒ–ä»ªè¡¨æ¿
- è¶‹åŠ¿åˆ†æ

ä¾èµ–é¡¹
------
- Python 3.7+
- matplotlib (å¯é€‰ï¼Œç”¨äºå›¾è¡¨ç”Ÿæˆ)
- sqlite3 (å†…ç½®)
- threading (å†…ç½®)
- json (å†…ç½®)
"""

# ç‰ˆæœ¬ä¿¡æ¯
__version__ = "1.0.0"
__author__ = "S9å¼€å‘å›¢é˜Ÿ"
__description__ = "ä¼ä¸šçº§æœåŠ¡çŠ¶æ€èšåˆå’Œç›‘æ§ç³»ç»Ÿ"
__email__ = "s9-team@company.com"
__license__ = "MIT"

# å¯¼å…¥æ‰€æœ‰æ ¸å¿ƒç±»å’Œæšä¸¾
from .ServiceStatusAggregator import (
    # æšä¸¾ç±»
    ServiceStatus,
    AlertLevel,
    
    # æ•°æ®ç±»
    ServiceInfo,
    AlertInfo,
    StatusReport,
    
    # æ ¸å¿ƒç»„ä»¶
    StatusCollector,
    DataAggregator,
    StatusAnalyzer,
    AlertSystem,
    HistoryManager,
    ReportGenerator,
    StatusMonitor,
    Dashboard,
    ServiceStatusAggregator,
    
    # ç¤ºä¾‹å‡½æ•°
    example_service_collector
)

# é»˜è®¤é…ç½®
DEFAULT_CONFIG = {
    # æ•°æ®åº“é…ç½®
    "database": {
        "path": "service_status_history.db",
        "backup_enabled": True,
        "cleanup_days": 30
    },
    
    # ç›‘æ§é…ç½®
    "monitoring": {
        "check_interval": 30,  # ç§’
        "concurrent_workers": 5,
        "timeout": 10,  # ç§’
        "retry_count": 3
    },
    
    # é˜ˆå€¼é…ç½®
    "thresholds": {
        "response_time_warning": 2.0,  # ç§’
        "response_time_critical": 5.0,
        "error_count_warning": 3,
        "error_count_critical": 5,
        "availability_warning": 95.0,  # ç™¾åˆ†æ¯”
        "availability_critical": 90.0
    },
    
    # é¢„è­¦é…ç½®
    "alerting": {
        "enabled": True,
        "max_alerts_per_service": 10,
        "alert_cooldown": 300,  # ç§’
        "notification_channels": ["console", "log"]
    },
    
    # æŠ¥å‘Šé…ç½®
    "reporting": {
        "auto_generate": True,
        "interval": 3600,  # ç§’
        "formats": ["json", "html"],
        "include_charts": True
    },
    
    # å¯è§†åŒ–é…ç½®
    "dashboard": {
        "chart_theme": "default",
        "chart_width": 1200,
        "chart_height": 800,
        "dpi": 300,
        "colors": {
            "healthy": "#4CAF50",
            "warning": "#FF9800", 
            "critical": "#F44336",
            "offline": "#9E9E9E",
            "unknown": "#2196F3"
        }
    }
}

# å¸¸é‡å®šä¹‰
class Constants:
    """ç³»ç»Ÿå¸¸é‡å®šä¹‰"""
    
    # çŠ¶æ€å¸¸é‡
    STATUS_HEALTHY = "healthy"
    STATUS_WARNING = "warning"
    STATUS_CRITICAL = "critical"
    STATUS_OFFLINE = "offline"
    STATUS_UNKNOWN = "unknown"
    
    # é¢„è­¦çº§åˆ«å¸¸é‡
    ALERT_INFO = "info"
    ALERT_WARNING = "warning"
    ALERT_CRITICAL = "critical"
    
    # æ–‡ä»¶æ‰©å±•å
    EXT_JSON = ".json"
    EXT_HTML = ".html"
    EXT_CSV = ".csv"
    EXT_PNG = ".png"
    EXT_DB = ".db"
    
    # æ—¶é—´æ ¼å¼
    TIME_FORMAT = "%Y-%m-%d %H:%M:%S"
    TIMESTAMP_FORMAT = "%Y%m%d_%H%M%S"
    
    # æ•°æ®åº“è¡¨å
    TABLE_SERVICE_HISTORY = "service_status_history"
    TABLE_ALERT_HISTORY = "alert_history"
    
    # é»˜è®¤å€¼
    DEFAULT_CHECK_INTERVAL = 30  # ç§’
    DEFAULT_RESPONSE_TIMEOUT = 10  # ç§’
    DEFAULT_HISTORY_DAYS = 30  # å¤©
    DEFAULT_MAX_ALERTS = 100
    
    # APIç«¯ç‚¹
    ENDPOINT_STATUS = "/api/status"
    ENDPOINT_HEALTH = "/health"
    ENDPOINT_METRICS = "/metrics"

# ä¾¿åˆ©å‡½æ•°
def create_aggregator(config: dict = None, db_path: str = None) -> ServiceStatusAggregator:
    """
    åˆ›å»ºçŠ¶æ€èšåˆå™¨å®ä¾‹çš„ä¾¿åˆ©å‡½æ•°
    
    Args:
        config: è‡ªå®šä¹‰é…ç½®å­—å…¸ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
    
    Returns:
        ServiceStatusAggregator: é…ç½®å¥½çš„èšåˆå™¨å®ä¾‹
    """
    # åˆå¹¶é…ç½®
    final_config = DEFAULT_CONFIG.copy()
    if config:
        final_config.update(config)
    
    # åˆ›å»ºèšåˆå™¨
    db_path = db_path or final_config["database"]["path"]
    aggregator = ServiceStatusAggregator(db_path)
    
    return aggregator

def quick_monitor(service_configs: list, interval: int = 30) -> ServiceStatusAggregator:
    """
    å¿«é€Ÿè®¾ç½®ç›‘æ§çš„ä¾¿åˆ©å‡½æ•°
    
    Args:
        service_configs: æœåŠ¡é…ç½®åˆ—è¡¨ï¼Œæ¯ä¸ªé…ç½®åŒ…å«service_id, name, endpoint, collector_func
        interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
    
    Returns:
        ServiceStatusAggregator: é…ç½®å¥½çš„èšåˆå™¨å®ä¾‹
    
    Example:
        >>> def my_service_check():
        ...     return {"status": ServiceStatus.HEALTHY, "response_time": 0.5}
        >>> 
        >>> configs = [
        ...     {
        ...         "service_id": "web_service",
        ...         "name": "WebæœåŠ¡", 
        ...         "endpoint": "http://localhost:8080",
        ...         "collector_func": my_service_check
        ...     }
        ... ]
        >>> 
        >>> aggregator = quick_monitor(configs, interval=30)
        >>> aggregator.start_monitoring()
    """
    aggregator = create_aggregator()
    
    # æ³¨å†ŒæœåŠ¡
    for config in service_configs:
        aggregator.register_service(
            service_id=config["service_id"],
            name=config["name"],
            endpoint=config["endpoint"],
            collector_func=config["collector_func"],
            metadata=config.get("metadata", {})
        )
    
    # å¼€å§‹ç›‘æ§
    aggregator.start_monitoring(interval)
    
    return aggregator

def generate_sample_report(output_file: str = "sample_report.html") -> StatusReport:
    """
    ç”Ÿæˆç¤ºä¾‹æŠ¥å‘Šçš„ä¾¿åˆ©å‡½æ•°
    
    Args:
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    
    Returns:
        StatusReport: ç”Ÿæˆçš„çŠ¶æ€æŠ¥å‘Š
    
    Example:
        >>> report = generate_sample_report("my_report.html")
        >>> print(report.summary)
    """
    aggregator = create_aggregator()
    
    # æ³¨å†Œç¤ºä¾‹æœåŠ¡
    aggregator.register_service(
        service_id="example_service",
        name="ç¤ºä¾‹æœåŠ¡",
        endpoint="http://localhost:8080",
        collector_func=example_service_collector
    )
    
    # æ”¶é›†çŠ¶æ€å¹¶ç”ŸæˆæŠ¥å‘Š
    aggregator.collect_status()
    report = aggregator.generate_report()
    
    # å¯¼å‡ºæŠ¥å‘Š
    if output_file.endswith('.html'):
        html_content = aggregator.report_generator.export_report_html(report)
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
    elif output_file.endswith('.json'):
        json_content = aggregator.report_generator.export_report_json(report)
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(json_content)
    
    return report

def health_check_summary(aggregator: ServiceStatusAggregator) -> dict:
    """
    è·å–å¥åº·æ£€æŸ¥æ‘˜è¦çš„ä¾¿åˆ©å‡½æ•°
    
    Args:
        aggregator: çŠ¶æ€èšåˆå™¨å®ä¾‹
    
    Returns:
        dict: å¥åº·æ£€æŸ¥æ‘˜è¦ä¿¡æ¯
    
    Example:
        >>> aggregator = create_aggregator()
        >>> # ... æ³¨å†Œå¹¶æ”¶é›†æœåŠ¡çŠ¶æ€
        >>> summary = health_check_summary(aggregator)
        >>> print(f"ç³»ç»Ÿå¥åº·åº¦: {summary['health_rate']:.1f}%")
    """
    metrics = aggregator.get_aggregated_metrics()
    
    if not metrics:
        return {"status": "no_data", "message": "æš‚æ— æœåŠ¡æ•°æ®"}
    
    total = metrics.get("total_services", 0)
    if total == 0:
        return {"status": "no_services", "message": "æœªæ³¨å†Œä»»ä½•æœåŠ¡"}
    
    # è®¡ç®—å¥åº·åº¦ï¼ˆåŸºäºçŠ¶æ€åˆ†å¸ƒï¼‰
    status_dist = metrics.get("status_distribution", {})
    healthy_count = status_dist.get("healthy", 0)
    health_rate = (healthy_count / total) * 100
    
    # ç¡®å®šæ•´ä½“çŠ¶æ€
    if health_rate >= 90:
        overall_status = "excellent"
    elif health_rate >= 70:
        overall_status = "good"
    elif health_rate >= 50:
        overall_status = "warning"
    else:
        overall_status = "critical"
    
    return {
        "overall_status": overall_status,
        "health_rate": health_rate,
        "total_services": total,
        "healthy_services": healthy_count,
        "warning_services": status_dist.get("warning", 0),
        "critical_services": status_dist.get("critical", 0),
        "offline_services": status_dist.get("offline", 0),
        "avg_response_time": metrics.get("avg_response_time", 0),
        "timestamp": metrics.get("timestamp").isoformat() if metrics.get("timestamp") else None
    }

# å¿«é€Ÿå…¥é—¨æŒ‡å—
QUICK_START_GUIDE = """
å¿«é€Ÿå…¥é—¨æŒ‡å—
============

1. åŸºæœ¬ä½¿ç”¨
-----------

```python
from S9 import create_aggregator, ServiceStatus, example_service_collector

# åˆ›å»ºèšåˆå™¨
aggregator = create_aggregator()

# æ³¨å†ŒæœåŠ¡
aggregator.register_service(
    service_id="my_service",
    name="æˆ‘çš„æœåŠ¡",
    endpoint="http://localhost:8080",
    collector_func=example_service_collector
)

# æ”¶é›†çŠ¶æ€
services = aggregator.collect_status()
print("æœåŠ¡çŠ¶æ€:", {sid: service.status.value for sid, service in services.items()})

# ç”ŸæˆæŠ¥å‘Š
report = aggregator.generate_report()
print("ç³»ç»Ÿæ‘˜è¦:", report.summary)
```

2. ç›‘æ§è®¾ç½®
-----------

```python
from S9 import quick_monitor

# å®šä¹‰æœåŠ¡æ£€æŸ¥å‡½æ•°
def check_my_service():
    import requests
    try:
        response = requests.get("http://localhost:8080/health", timeout=5)
        return {
            "status": ServiceStatus.HEALTHY if response.status_code == 200 else ServiceStatus.CRITICAL,
            "response_time": response.elapsed.total_seconds()
        }
    except:
        return {
            "status": ServiceStatus.OFFLINE,
            "response_time": 0
        }

# å¿«é€Ÿè®¾ç½®ç›‘æ§
configs = [{
    "service_id": "my_service",
    "name": "æˆ‘çš„æœåŠ¡",
    "endpoint": "http://localhost:8080", 
    "collector_func": check_my_service
}]

aggregator = quick_monitor(configs, interval=30)
```

3. é¢„è­¦é…ç½®
-----------

```python
from S9 import AlertLevel

# æ·»åŠ è‡ªå®šä¹‰é¢„è­¦å›è°ƒ
def my_alert_callback(alert):
    print(f"ğŸš¨ è‡ªå®šä¹‰é¢„è­¦: {alert.level.value} - {alert.message}")
    # è¿™é‡Œå¯ä»¥æ·»åŠ é‚®ä»¶é€šçŸ¥ã€Slackæ¶ˆæ¯ç­‰

aggregator.alert_system.add_alert_callback(my_alert_callback)

# æ·»åŠ é¢„è­¦è§„åˆ™
def check_response_time(service_info):
    if service_info.response_time > 5.0:
        return True
    return False

aggregator.alert_system.add_alert_rule("response_time", check_response_time)
```

4. æ•°æ®å¯¼å‡º
-----------

```python
# å¯¼å‡ºä»ªè¡¨æ¿æ•°æ®
aggregator.export_dashboard_json("dashboard.json")

# ç”Ÿæˆå›¾è¡¨ï¼ˆéœ€è¦matplotlibï¼‰
charts = aggregator.generate_charts("./charts")
print("ç”Ÿæˆçš„å›¾è¡¨:", charts)

# å¯¼å‡ºHTMLæŠ¥å‘Š
report = aggregator.generate_report()
html_content = aggregator.report_generator.export_report_html(report)
with open("status_report.html", "w", encoding="utf-8") as f:
    f.write(html_content)
```

5. å†å²æ•°æ®åˆ†æ
---------------

```python
# è·å–æœåŠ¡å†å²æ•°æ®
history = aggregator.history_manager.get_service_history("my_service", hours=24)
print("è¿‡å»24å°æ—¶è®°å½•æ•°:", len(history))

# è·å–è¶‹åŠ¿åˆ†æ
trend = aggregator.data_aggregator.get_trend_analysis("response_time", hours=24)
print("å“åº”æ—¶é—´è¶‹åŠ¿:", trend["trend"])
```

6. é…ç½®è‡ªå®šä¹‰
------------

```python
custom_config = {
    "monitoring": {
        "check_interval": 15,  # 15ç§’æ£€æŸ¥ä¸€æ¬¡
        "timeout": 5
    },
    "thresholds": {
        "response_time_warning": 1.0,
        "response_time_critical": 3.0
    }
}

aggregator = create_aggregator(config=custom_config)
```

æ³¨æ„äº‹é¡¹
--------
- ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–é¡¹ï¼ˆç‰¹åˆ«æ˜¯matplotlibç”¨äºå›¾è¡¨ç”Ÿæˆï¼‰
- æ•°æ®åº“æ–‡ä»¶ä¼šè‡ªåŠ¨åˆ›å»ºï¼Œæ³¨æ„æ–‡ä»¶æƒé™
- å¤§é‡æœåŠ¡ç›‘æ§æ—¶è€ƒè™‘æ€§èƒ½å½±å“
- ç”Ÿäº§ç¯å¢ƒå»ºè®®é…ç½®æ—¥å¿—çº§åˆ«ä¸ºWARNINGæˆ–ERROR
- å®šæœŸæ¸…ç†å†å²æ•°æ®ä»¥é¿å…æ•°æ®åº“è¿‡å¤§
"""

# æ¨¡å—å…ƒæ•°æ®
__all__ = [
    # ç‰ˆæœ¬ä¿¡æ¯
    "__version__",
    "__author__", 
    "__description__",
    
    # æ ¸å¿ƒç±»
    "ServiceStatus",
    "AlertLevel", 
    "ServiceInfo",
    "AlertInfo",
    "StatusReport",
    "StatusCollector",
    "DataAggregator",
    "StatusAnalyzer", 
    "AlertSystem",
    "HistoryManager",
    "ReportGenerator",
    "StatusMonitor",
    "Dashboard",
    "ServiceStatusAggregator",
    
    # ä¾¿åˆ©å‡½æ•°
    "create_aggregator",
    "quick_monitor", 
    "generate_sample_report",
    "health_check_summary",
    
    # é…ç½®å’Œå¸¸é‡
    "DEFAULT_CONFIG",
    "Constants",
    "QUICK_START_GUIDE",
    
    # ç¤ºä¾‹å‡½æ•°
    "example_service_collector"
]

# æ¨¡å—åˆå§‹åŒ–æ—¥å¿—
import logging
logger = logging.getLogger(__name__)
logger.info(f"S9çŠ¶æ€èšåˆå™¨æ¨¡å—å·²åŠ è½½ - ç‰ˆæœ¬: {__version__}")

# æ¨¡å—æ£€æŸ¥
def check_dependencies():
    """æ£€æŸ¥ä¾èµ–é¡¹æ˜¯å¦æ»¡è¶³"""
    missing_deps = []
    
    try:
        import matplotlib
        logger.info("âœ“ matplotlibå·²å®‰è£…")
    except ImportError:
        missing_deps.append("matplotlib")
        logger.warning("âš  matplotlibæœªå®‰è£…ï¼Œå›¾è¡¨åŠŸèƒ½å°†ä¸å¯ç”¨")
    
    try:
        import sqlite3
        logger.info("âœ“ sqlite3å¯ç”¨")
    except ImportError:
        missing_deps.append("sqlite3")
    
    try:
        import threading
        logger.info("âœ“ threadingå¯ç”¨")
    except ImportError:
        missing_deps.append("threading")
    
    if missing_deps:
        logger.warning(f"ç¼ºå°‘ä¾èµ–é¡¹: {', '.join(missing_deps)}")
        return False
    else:
        logger.info("æ‰€æœ‰ä¾èµ–é¡¹æ£€æŸ¥é€šè¿‡")
        return True

# å¯åŠ¨æ—¶è‡ªåŠ¨æ£€æŸ¥ä¾èµ–
if __name__ != "__main__":
    check_dependencies()